{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "mode = 'bc'\n",
    "if (mode == 'bc'):\n",
    "    os.environ['PYSPARK_PYTHON'] = './python3.6.2/bin/python'\n",
    "    os.environ['HADOOP_USER_NAME'] = 'bigdata_driver_ecosys_test'\n",
    "    os.environ['HADOOP_USER_PASSWORD'] = '42gdaTh6voXDV0mR2glhNPjWqBxYe22N'\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark import *\n",
    "    from pyspark.sql import *\n",
    "    app_name = 'get_list_of_city_transf43'\n",
    "    conf = (SparkConf().setAppName(app_name)\n",
    "            .set('spark.master', 'yarn')\n",
    "            .set('spark.submit.deployMode', 'client')\n",
    "            .set('spark.driver.memory',                  '4g')\n",
    "            .set('spark.executor.memory',                '12g')\n",
    "            .set('spark.dynamicAllocation.minExecutors', '10')\n",
    "            .set('spark.driver.maxResultSize' ,           '0')\n",
    "            .set('spark.dynamicAllocation.maxExecutors', '200')\n",
    "            .set('spark.yarn.queue',                     'root.kg_novel_dev')\n",
    "            .set('spark.ui.port','8060')\n",
    "            .set('spark.yarn.executor.memoryOverhead','3000m')\n",
    "            .set('spark.yarn.dist.archives','hdfs://DClusterNmg4/user/bigdata_driver_ecosys_test/ly/python_env/python3.6.2.tgz#python3.6.2 ')\n",
    "            .set('spark.pyspark.driver.python',          './python3.6.2/bin/python')\n",
    "            .set('spark.pyspark.python', './python3.6.2/bin/python')\n",
    "            .set(\"spark.yarn.appMasterEnv.PYSPARK_PYTHON\", './python3.6.2/bin/python')\n",
    "            )\n",
    "    spark = SparkSession.builder.config(conf = conf).enableHiveSupport().getOrCreate()\n",
    "    # spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)\n",
    "    sc = spark.sparkContext\n",
    "from pyspark.sql.functions import col,udf,date_sub,explode,split,date_add\n",
    "from pyspark.sql.types import StringType,DoubleType,IntegerType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('expand_frame_repr',False)\n",
    "from pyspark.sql import functions as F\n",
    "hc = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "webhook = 'https://im-dichat.xiaojukeji.com/api/hooks/incoming/c64821f6-36b7-4a5d-8375-f740ac63b448'\n",
    "\n",
    "dapan_sql = '''\n",
    "select\n",
    "  *\n",
    "from smt_stg.smt_budget_alloc_dapan_t2\n",
    "where\n",
    "  dt = '{dt}'\n",
    "'''\n",
    "\n",
    "city_sql = '''\n",
    "select \n",
    "  city_id,\n",
    "  city_name,\n",
    "  gmv_type\n",
    "from smt_stg.smt_mps_city_info\n",
    "'''\n",
    "\n",
    "gmv_sql = '''\n",
    "select\n",
    "  city_id,\n",
    "  sum(case when product_id = 110103  then gmv else 0.0 end ) as th_gmv,\n",
    "  sum(case when product_id = 110101  then gmv else 0.0 end ) as pk_gmv\n",
    "from mp_data.dm_trip_mp_sd_core_1d\n",
    "where\n",
    "  dt = '{dt}'\n",
    "  and product_id in (110101, 110103)\n",
    "group by city_id\n",
    "'''\n",
    "\n",
    "pred_sql = '''\n",
    "select\n",
    "  a.city_id city_id,\n",
    "  pred_gmv,\n",
    "  pred_obj_cr,\n",
    "  pred_pk_gmv,\n",
    "  pred_th_gmv\n",
    "from (\n",
    "select  city_id\n",
    "        ,sum(if(key_id = 'gmv',estimate_value,0)) as pred_gmv\n",
    "        ,sum(if(key_id = 'objective_exp_openapi_pp',estimate_value,0)) as pred_obj_cr\n",
    "from    mp_data.app_trip_mkt_supply_demand_forecast_result_di\n",
    "where   estimate_date = '{estimate_date}'\n",
    "        and datediff(estimate_date, dt) = {diff}\n",
    "        and product_name = '泛快含优不含拼（快车（普通快车、A+、车大、巡游网约车）、优享、D1、特惠快车、涅槃）'\n",
    "group by city_id\n",
    ") a join (\n",
    "select  city_id\n",
    "        ,sum(if(product_name = '快车' and key_id = 'gmv',estimate_value,0)) as pred_pk_gmv\n",
    "        ,sum(if(product_name = '特惠自营' and key_id = 'gmv',estimate_value,0)) as pred_th_gmv\n",
    "from    mp_data.app_trip_mkt_supply_demand_forecast_result_di\n",
    "where   estimate_date = '{estimate_date}'\n",
    "        and datediff(estimate_date, dt) = {diff}\n",
    "        and product_name in ('快车', '特惠自营')\n",
    "group by city_id\n",
    ") b on a.city_id = b.city_id\n",
    "'''\n",
    "\n",
    "pred_roi_sql = '''\n",
    "select\n",
    "    city_id,\n",
    "    pred_roi,\n",
    "    combo_subsidy_rate\n",
    "from smt_stg.budget_allocation_pred_delta_gmv_v2\n",
    "where \n",
    "    concat_ws('-', year, month, day)='{dt}' \n",
    "    and version = 'roi_lgb_v1'\n",
    "'''\n",
    "real_roi_sql = '''\n",
    "select\n",
    "    exp.city_id as city_id\n",
    "    ,(exp.avg_gmv - ctl.avg_gmv)/(exp.avg_c - ctl.avg_c) as real_roi\n",
    "from\n",
    "    (select\n",
    "        city_id,\n",
    "        gmv/group_usr_num as avg_gmv,\n",
    "        subsidy_c/group_usr_num as avg_c\n",
    "    from smt_stg.budget_allocation_xfk_city_daily_table\n",
    "    where group_name='rgroup_joint_exp_pack'\n",
    "          and product_line = '新泛快'\n",
    "          and dt = '{dt}'\n",
    "    ) exp join\n",
    "    (select\n",
    "        city_id,\n",
    "        gmv/group_usr_num as avg_gmv,\n",
    "        subsidy_c/group_usr_num as avg_c\n",
    "    from smt_stg.budget_allocation_xfk_city_daily_table\n",
    "    where group_name='rgroup_joint_blank'\n",
    "          and product_line = '新泛快'\n",
    "          and dt = '{dt}'\n",
    "    ) ctl on exp.city_id = ctl.city_id\n",
    "'''\n",
    "\n",
    "exp_hf_sql = '''\n",
    "select\n",
    "  a.city as city_id,\n",
    "  exp_pkhf,\n",
    "  exp_thhf\n",
    "from\n",
    "(select\n",
    "    dt --日期\n",
    "    , city --城市\n",
    "    , JSON_EXTRACT(target_info, '$.rate') as exp_pkhf\n",
    "from\n",
    "    ppe.budget_amount_record\n",
    "where\n",
    "    dt = '{dt}'\n",
    "    and amount_type='exp_budget'\n",
    "    and  tuple_info like '{group}'\n",
    "    and product_line = 'kuaiche'\n",
    ") a join\n",
    "(select\n",
    "    dt --日期\n",
    "    , city --城市\n",
    "    , JSON_EXTRACT(target_info, '$.rate') as exp_thhf\n",
    "from\n",
    "    ppe.budget_amount_record\n",
    "where\n",
    "    dt = '{dt}'\n",
    "    and amount_type='exp_budget'\n",
    "    and  tuple_info like '{group}'\n",
    "    and product_line = 'tehui'\n",
    ") b on a.dt = b.dt and a.city = b.city\n",
    "'''\n",
    "\n",
    "insert_sql = '''\n",
    "insert overwrite table\n",
    "    smt_stg.smt_err_budget_alloc_sum_t1\n",
    "partition\n",
    "    (dt = '{dt}')\n",
    "select\n",
    "    source_type,\n",
    "    err_type,\n",
    "    city_cnt,\n",
    "    gmv,\n",
    "    fkhf_amount,\n",
    "    mid_cr,\n",
    "    mid_fkhf,\n",
    "    city_total,\n",
    "    gmv_total,\n",
    "    fkhf_total\n",
    "from {tmp}\n",
    "'''\n",
    "\n",
    "insert_city_sql = '''\n",
    "insert overwrite table\n",
    "    smt_stg.smt_err_budget_alloc_city_t1\n",
    "partition\n",
    "    (dt = '{dt}')\n",
    "select\n",
    "    city_id,\n",
    "    city_name,\n",
    "    city_type,\n",
    "    gmv_type,\n",
    "    demand,\n",
    "    source_type,\n",
    "    err_type,\n",
    "    gmv,\n",
    "    exp_cr,\n",
    "    fkhf,\n",
    "    pred_gmv,\n",
    "    target_fkhf,\n",
    "    obj_cr,\n",
    "    pred_obj_cr,\n",
    "    cr_diff,\n",
    "    fkhf_diff,\n",
    "    diag1,\n",
    "    diag2,\n",
    "    diag3,\n",
    "    diag4,\n",
    "    pred_roi,\n",
    "    real_roi,\n",
    "    obj_cr_diff,\n",
    "    pred_obj_cr_diff,\n",
    "    algo_fkhf,\n",
    "    algo_fkhf_diff,\n",
    "    algo_err_type,\n",
    "    case_level,\n",
    "    is_manual\n",
    "from {tmp}\n",
    "'''\n",
    "\n",
    "\n",
    "class DChatRobot:\n",
    "    \"\"\"DChatRobot\"\"\"\n",
    "\n",
    "    def __init__(self, webhook):\n",
    "        super(DChatRobot, self).__init__()\n",
    "        self.webhook = webhook\n",
    "\n",
    "    def send_message(self, title, content_list, is_md=True):\n",
    "        data = {\n",
    "            \"text\": title,\n",
    "            \"markdown\": is_md,\n",
    "            \"attachments\": content_list\n",
    "        }\n",
    "        return self.post(data)\n",
    "\n",
    "    def post(self, data):\n",
    "        post_data = json.dumps({\n",
    "            \"web_hook\": self.webhook,\n",
    "            \"data\": data\n",
    "        })\n",
    "        print(post_data)\n",
    "        HEADERS = {\"Content-Type\": \"application/json ;charset=utf-8 \"}\n",
    "        req = requests.post(\"http://10.74.113.54:8021/stg/dchat_notification\", post_data,\n",
    "                            headers=HEADERS)\n",
    "\n",
    "\n",
    "def get_badcase_by_mean(df, by_category=True, hf_col='', diag_col=''):\n",
    "    gmv_types = ['']\n",
    "    if by_category:\n",
    "        gmv_types = [('特大城市', '大城市', '中城市'), ('小城市', '尾部城市')]\n",
    "    dfs = []\n",
    "    for g_type in gmv_types:\n",
    "        df1 = df[df.gmv_type.isin(g_type)] if by_category else df.copy()\n",
    "        df1 = df1.reset_index(drop=True)\n",
    "        m_hf_col = 'm_' + hf_col\n",
    "        hf_diff_col = hf_col + '_diff'\n",
    "        df1[m_hf_col] = df1[hf_col].median()\n",
    "        df1['m_cr'] = df1.exp_cr.median()\n",
    "        df1[hf_diff_col] = (df1[hf_col] - df1[m_hf_col]) / df1[m_hf_col]\n",
    "        df1['cr_diff'] = (df1.exp_cr - df1.m_cr) / df1.m_cr\n",
    "        # add more cr diff\n",
    "        df1['m_obj_cr'] = df1.obj_cr.median()\n",
    "        df1['obj_cr_diff'] = (df1.obj_cr - df1.m_obj_cr) / df1.m_obj_cr\n",
    "        df1['m_pred_obj_cr'] = df1.pred_obj_cr.median()\n",
    "        df1['pred_obj_cr_diff'] = (df1.pred_obj_cr - df1.m_pred_obj_cr) / df1.m_pred_obj_cr\n",
    "        df1[diag_col] = '正常'\n",
    "        for i, row in df1.iterrows():\n",
    "            dcr, dhf = row.cr_diff, row[hf_diff_col]\n",
    "            diag = '正常'\n",
    "            if dcr > 0.03 and dhf < -0.0 and row.real_roi > 1:\n",
    "                diag = '严重漏补'\n",
    "            elif dcr > 0.0 and dhf < -0.5 and row.real_roi > 1:\n",
    "                diag = '中等漏补'\n",
    "            elif dcr > 0.0 and dhf < -0.05 and row.real_roi > 1:\n",
    "                diag = '轻度漏补'\n",
    "            elif dcr < -0.05 and row.fkhf > 0.01:\n",
    "                diag = '严重误补'\n",
    "            elif dcr < -0.0 and dhf > 0.5:\n",
    "                diag = '中等误补'\n",
    "            elif dcr < -0.0 and dhf > 0.05:\n",
    "                diag = '轻度误补'\n",
    "            row[diag_col] = diag\n",
    "            df1.iloc[i] = row\n",
    "        dfs.append(df1)\n",
    "    odf = pd.concat(dfs)\n",
    "    return odf\n",
    "\n",
    "\n",
    "def cr_diag(row):\n",
    "    pred_diff = row.pred_obj_cr - row.obj_cr\n",
    "    if row.err_type == '正常':\n",
    "        return row\n",
    "    elif '误补' in row.err_type:\n",
    "        if pred_diff > 0.07:\n",
    "            row.diag1 = 1\n",
    "        if pred_diff > 0.05:\n",
    "            row.diag2 = 1\n",
    "        if pred_diff > 0.03:\n",
    "            row.diag3 = 1\n",
    "        if (row.obj_cr < 0.72 and row.pred_obj_cr > 0.72 and pred_diff > 0.03) or (\n",
    "                row.obj_cr > 0.72 and pred_diff > 0.05):\n",
    "            row.diag4 = 1\n",
    "    elif '漏补' in row.err_type:\n",
    "        if pred_diff < -0.07:\n",
    "            row.diag1 = 1\n",
    "        if pred_diff < -0.05:\n",
    "            row.diag2 = 1\n",
    "        if pred_diff < -0.03:\n",
    "            row.diag3 = 1\n",
    "        if (row.obj_cr > 0.8 and row.pred_obj_cr < 0.8 and pred_diff < -0.04) or (\n",
    "                row.obj_cr < 0.8 and pred_diff < -0.05):\n",
    "            row.diag4 = 1\n",
    "    return row\n",
    "\n",
    "\n",
    "def get_case_level(row):\n",
    "    if row.gmv_type == '大城市' and '严重' in row.err_type:\n",
    "        row.case_level = 'P0'\n",
    "    elif (row.gmv_type == '大城市' and '中等' in row.err_type) or (\n",
    "            row.gmv_type == '中城市' and '严重' in row.err_type):\n",
    "        row.case_level = 'P1'\n",
    "    elif '正常' in row.err_type:\n",
    "        row.case_level = '/'\n",
    "    else:\n",
    "        row.case_level = 'P2'\n",
    "    return row\n",
    "\n",
    "\n",
    "def main(day):\n",
    "    # spark = SparkSession.builder.appName(\n",
    "    #     'pukuai_tehui_zhuanche_dgmv_pred daily inference').enableHiveSupport().getOrCreate()\n",
    "    # spark.conf.set('spark.sql.broadcastTimeout', 360000)\n",
    "    # spark.conf.set('hive.exec.dynamic.partition.mode', 'nonstrict')\n",
    "    # spark.sql('set spark.sql.hive.convertMetastoreOrc=true')\n",
    "    # spark.sql('set spark.sql.orc.impl=native')\n",
    "    # spark.sql('set dfs.client.socket-timeout=600000')\n",
    "    # sc = spark.sparkContext\n",
    "    # hc = HiveContext(sc)\n",
    "\n",
    "    # yesterday = '${BIZ_DATE_LINE}'\n",
    "    yesterday = day\n",
    "    df = hc.sql(dapan_sql.format(dt=yesterday)).toPandas()\n",
    "    city_df = hc.sql(city_sql).toPandas()\n",
    "    df = pd.merge(df, city_df, on='city_id', how='left')\n",
    "    df = df[df.city_type == '非战区非下沉']\n",
    "    for i in range(1, 3):\n",
    "        pred_df = hc.sql(pred_sql.format(estimate_date=yesterday, diff=i)).toPandas()\n",
    "        if not pred_df.empty:\n",
    "            break\n",
    "    df = pd.merge(df, pred_df, how='left', on='city_id')\n",
    "    gmv_df = hc.sql(gmv_sql.format(dt=yesterday)).toPandas()\n",
    "    df = pd.merge(df, gmv_df, how='left', on='city_id')\n",
    "    df = df.fillna('0').astype({\n",
    "        'gmv': 'float',\n",
    "        'exp_cr': 'float',\n",
    "        'intelligent_subsidy_c': 'float',\n",
    "        'real_thhf': 'float',\n",
    "        'real_pkhf': 'float',\n",
    "        'algo_thhf': 'float',\n",
    "        'algo_pkhf': 'float',\n",
    "        'obj_cr': 'float',\n",
    "        'pred_obj_cr': 'float',\n",
    "        'pred_pk_gmv': 'float',\n",
    "        'pred_th_gmv': 'float',\n",
    "        'pred_gmv': 'float',\n",
    "        'pk_gmv': 'float',\n",
    "        'th_gmv': 'float',\n",
    "    })\n",
    "    real_roi_df = hc.sql(real_roi_sql.format(dt=yesterday)).toPandas()\n",
    "    df = pd.merge(df, real_roi_df, how='left', on='city_id')\n",
    "    df['real_roi'] = df.real_roi.fillna(0)\n",
    "    df['fkhf'] = df.intelligent_subsidy_c / df.gmv\n",
    "\n",
    "    df['target_fkhf'] = (df.pred_pk_gmv * df.real_pkhf + df.pred_th_gmv * df.real_thhf) / df.pred_gmv\n",
    "    df['algo_fkhf'] = (df.pred_pk_gmv * df.algo_pkhf + df.pred_th_gmv * df.algo_thhf) / df.pred_gmv\n",
    "    # 判断 bad case\n",
    "    df = get_badcase_by_mean(df, True, 'algo_fkhf', 'algo_err_type')\n",
    "    df = get_badcase_by_mean(df, True, 'fkhf', 'err_type')\n",
    "\n",
    "    # 实验组补贴率和 badcase\n",
    "    group = \"%rgroup_zyfp_kt_exp1%\"\n",
    "    exp_df = hc.sql(exp_hf_sql.format(dt=yesterday, group=group)).toPandas()\n",
    "    df = pd.merge(df, exp_df, how='left', on='city_id')\n",
    "    df = df.astype({\n",
    "        'exp_pkhf': 'float',\n",
    "        'exp_thhf': 'float',\n",
    "    })\n",
    "    df['exp_fkhf'] = (df.pred_pk_gmv * df.exp_pkhf + df.pred_th_gmv * df.exp_thhf) / df.pred_gmv\n",
    "    df = get_badcase_by_mean(df, True, 'exp_fkhf', 'exp_err_type')\n",
    "\n",
    "    agg_df = df.groupby('err_type').agg({\n",
    "        'city_id': 'count',\n",
    "        'gmv': 'sum',\n",
    "        'intelligent_subsidy_c': 'sum',\n",
    "        'exp_cr': 'median',\n",
    "        'fkhf': 'median',\n",
    "    }).reset_index()\n",
    "    agg_df = agg_df.rename(columns={\n",
    "        'city_id': 'city_cnt',\n",
    "        'intelligent_subsidy_c': 'fkhf_amount',\n",
    "        'exp_cr': 'mid_cr',\n",
    "        'fkhf': 'mid_fkhf',\n",
    "    })\n",
    "    agg_df['source_type'] = '后验'\n",
    "    agg_df['city_total'] = df.city_id.count()\n",
    "    agg_df['gmv_total'] = df.gmv.sum()\n",
    "    agg_df['fkhf_total'] = df.intelligent_subsidy_c.sum()\n",
    "    # 总体统计\n",
    "    tmp_name = 'tmp_table'\n",
    "    spark.createDataFrame(agg_df[[\n",
    "        'source_type', 'err_type', 'city_cnt', 'gmv', 'fkhf_amount', 'mid_cr', 'mid_fkhf',\n",
    "        'city_total', 'gmv_total', 'fkhf_total'\n",
    "    ]].copy()).registerTempTable(tmp_name)\n",
    "    # hc.sql(insert_sql.format(dt=yesterday, tmp=tmp_name))\n",
    "    # 分城市统计\n",
    "    df = df.astype({\n",
    "        'pred_obj_cr': 'float',\n",
    "    })\n",
    "    df['source_type'] = '后验'\n",
    "    df['diag1'] = 0\n",
    "    df['diag2'] = 0\n",
    "    df['diag3'] = 0\n",
    "    df['diag4'] = 0\n",
    "    df = df.apply(cr_diag, axis=1)\n",
    "    pred_roi_df = hc.sql(pred_roi_sql.format(dt=yesterday)).toPandas()\n",
    "    rates_df = pred_roi_df['combo_subsidy_rate'].str.split(',', expand=True)\n",
    "    pred_roi_df['algo_pkhf'] = rates_df[0].astype('float')\n",
    "    pred_roi_df['algo_thhf'] = rates_df[1].astype('float')\n",
    "    df['algo_pkhf'] = df.algo_pkhf.round(3)\n",
    "    df['algo_thhf'] = df.algo_thhf.round(3)\n",
    "    df = pd.merge(df, pred_roi_df, how='left', on=['city_id', 'algo_pkhf', 'algo_thhf'])\n",
    "    df['pred_roi'] = df.pred_roi.fillna(0)\n",
    "    df['case_level'] = ''\n",
    "    df = df.apply(get_case_level, axis=1)\n",
    "    df['is_manual'] = abs(df.fkhf - df.algo_fkhf) > 0.5\n",
    "    df = df.astype({'is_manual': 'int'})\n",
    "\n",
    "    tmp_name = 'tmp_table1'\n",
    "    spark.createDataFrame(df[[\n",
    "        'city_id', 'city_name', 'city_type', 'gmv_type', 'demand', 'source_type', 'err_type', 'gmv',\n",
    "        'exp_cr', 'fkhf', 'pred_gmv', 'target_fkhf', 'obj_cr', 'pred_obj_cr', 'cr_diff',\n",
    "        'fkhf_diff', 'diag1', 'diag2', 'diag3', 'diag4', 'pred_roi', 'real_roi', 'obj_cr_diff',\n",
    "        'pred_obj_cr_diff', 'algo_fkhf', 'algo_fkhf_diff', 'algo_err_type', 'case_level',\n",
    "        'is_manual'\n",
    "    ]].copy()).registerTempTable(tmp_name)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>线上算法分配异常诊断</th>\n",
       "      <th>实验组1算法分配异常诊断</th>\n",
       "      <th>城市数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>正常</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>正常</td>\n",
       "      <td>正常</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>轻度漏补</td>\n",
       "      <td>正常</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>轻度漏补</td>\n",
       "      <td>轻度漏补</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>正常</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>中等误补</td>\n",
       "      <td>正常</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>正常</td>\n",
       "      <td>正常</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>轻度漏补</td>\n",
       "      <td>正常</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>轻度漏补</td>\n",
       "      <td>轻度漏补</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>正常</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>轻度误补</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt 线上算法分配异常诊断 实验组1算法分配异常诊断  城市数\n",
       "0  2023-05-10       中等误补         中等误补    1\n",
       "1  2023-05-10       中等误补           正常    1\n",
       "2  2023-05-10       中等误补         轻度误补    2\n",
       "3  2023-05-10         正常           正常   25\n",
       "4  2023-05-10       轻度漏补           正常    3\n",
       "5  2023-05-10       轻度漏补         轻度漏补    2\n",
       "6  2023-05-10       轻度误补           正常    1\n",
       "7  2023-05-10       轻度误补         轻度误补    2\n",
       "0  2023-05-11       中等误补         中等误补    2\n",
       "1  2023-05-11       中等误补           正常    3\n",
       "2  2023-05-11         正常           正常   25\n",
       "3  2023-05-11       轻度漏补           正常    4\n",
       "4  2023-05-11       轻度漏补         轻度漏补    1\n",
       "5  2023-05-11       轻度误补           正常    1\n",
       "6  2023-05-11       轻度误补         轻度误补    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for day in ('2023-05-10', '2023-05-11'):\n",
    "    df = main(day)\n",
    "    df = df[df.gmv_type.isin(['特大城市', '大城市', '中城市'])]\n",
    "    res = df.groupby(['algo_err_type', 'exp_err_type']).agg({'city_id': 'count'}).reset_index()\n",
    "    res.insert(0, 'dt', day)\n",
    "    #dfs.append(res[res.algo_err_type != res.exp_err_type])\n",
    "    dfs.append(res)\n",
    "out = pd.concat(dfs)\n",
    "out = out.rename(columns={\n",
    "        'algo_err_type': '线上算法分配异常诊断',\n",
    "        'exp_err_type': '实验组1算法分配异常诊断',\n",
    "        'city_id': '城市数',\n",
    "    })\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
